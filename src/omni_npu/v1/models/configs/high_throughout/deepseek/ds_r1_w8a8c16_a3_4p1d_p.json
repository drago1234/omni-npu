{
    "model_parallel_config": {
        "dense_mlp_tp_size": 4,
        "o_proj_tp_size": 1,
        "layer_parallel_config": {
            "self_attn.o_proj": {
                "tp_size_or_ranks": 16,
                "x_transform": {
                    "type": "None"
                },
                "y_transform": {
                    "type": "AllReduce",
                    "tp_size_or_ranks": 16
                }
            },
            "mlp.down_proj": {
                "tp_size_or_ranks": 16,
                "x_transform": {
                    "type": "None"
                },
                "y_transform": {
                    "type": "AllReduce",
                    "tp_size_or_ranks": 16
                }
            }
        },
        "input_split": true
    },
    "operator_optimization_config": {
        "enable_kv_rmsnorm_rope_cache": true,
        "prefill_moe_all_to_all": true,
        "best_ep": false,
        "merge_qkv": false,
        "gmm_nz": true,
        "control_accept_rate": -1,
        "enable_prefill_micro_batch": false,
        "experts_pruning": false
    }
}
